---
title: "Chan_Hou_Long_3035745312_P"
author: "Chan Hou Long, Guyver"
date: "12/12/2021"
output: 
  pdf_document: 
    number_sections: yes
    highlight: tango
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

```{r include=FALSE}
library(tidyverse)
library(scales)
library(mice)
library(caret)
library(MASS)
library(corrplot)
library(cowplot)
library(ggcorrplot)
library(ROCR)
library(ggplot2)
```

# Data importation
```{r}
setwd("~/Documents/HKU/STAT2604/proj")
customer <- read.table("Customer Data", header = TRUE, sep = ";")
```

The dataset has 2000 rows and 18 columns.
```{r}
dim(customer)
```

The 2 - 17 variables are the potential explanatory variables, the `Good_Customer` and `Bad_Customer` are the dependent variable. `ID` is the row number with an empty column `X`.
```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
str(customer)
```

Since `Good_Customer` and `Bad_Customer` are the same when a customer is defined as good, `Bad_Customer` is No and `Good_Customer` is Yes, we only take `Good_Customer` for the study. There is only 296 good customer with 1683 bad customers and 21 undefined.

```{r eval=FALSE, include=FALSE}
table(customer$Good_Customer)
table(customer$Bad_Customer)
```

## Data handling
[EDA q1]
After changing empty value as `NA` and character columns as factors, the mean of `Annual_Income` of customers is \$38003 with a maximum of 252193 and a minimum of 1377. They have applied for loans approximately twice in the past five years and currently held around 2 credit cards each. The maximum loan amount is 766612 and minimum 11020 with an average of 124010 among the customers. Most of them only have 1 or 2 family members that rely on themselves and `Number_of_Dependants` contains 246 missing values. The largest group of the employment level is part-time with 654 people. They have a mean of 17.56% of monthly gross earnings for monthly installments. With the largest 40% and smallest 15.2%, there are 24 NAs in `Installment_Percentage`. Most of the customers have around 7 years working years and 5 years living in the same places with an average age of 35.79. The majority of them do not miss or delay payments over the last 3 years and live on their own property. Most of them also have 1 extra line of credits and location 3 for receiving applications.

```{r}
customer[customer==""] <- NA
customer = customer[, 2:16]
customer[,7] = readr::parse_number(customer[,7])
customer[,6] = factor(customer[,6], levels = c("1", "2", "3", "4", "5"))
customer[,11:15] <- lapply(customer[,11:15], factor)
summary(customer)
```

Assuming data is MCAR, which missing completely at random, 5% of the total for large datasets is the safe maximum threshold. Since `Number_of_Dependants` is missing around 12.3%, NAs in this column should be dropped. `Installment_Percentage` and `Good_Customer` can keep as the percentage below 5%.

```{r}
per_of_missing <- function(x) {sum(is.na(x))/length(x)*100}
apply(customer, 2, per_of_missing)
```

# Error handling
[EDA q4]
After removing NAs in `Number_of_Dependantsin`, `Installment_Percentage` and `Good_Customer` keep below the percentage below 5%.

```{r}
customer = customer[!is.na(customer$Number_of_Dependants),]
# apply(customer, 2, per_of_missing)
```

Then, data will be imputed by using `mice()`. Dataframe `df` is created with 1754 rows and no NA values.

```{r include=FALSE}
impute <- mice(customer, m=5, seed = 5312)
```

```{r}
df <- complete(impute, 1)
# apply(apply(df,2,is.na),2,sum) ; nrow(df)
```

# Exploratory Analysis

From the bar chart, it is interesting to discover that customer who is labelled as bad customer normally has higher annual income than the good customer in all employment status.

```{r fig.height=2.5, fig.width=4}
ggplot(df, aes(x=Employment, y=Annual_Income, fill=Good_Customer)) + 
    geom_boxplot() + ylab("Annual Income") + labs(fill = "Good Customer")
```

From the density graph, both good and bad customers are right-skewed. However, the bad customer tends to have a smaller installment percentage compared to the good customer.

```{r fig.height=2.5, fig.width=4}
ggplot(df, aes(x = Installment_Percentage, fill = Good_Customer)) +
  geom_density(alpha=0.8) + ggtitle("Installment Percentage") +
  xlab("Installment Percentage") + labs(fill = "Good Customer")
```

## Correlation analysis
[EDA q2, q3]
From the below two plots of the correlation matrix, it can be seen that the top 3 variables associated with `Good_Customer` with the largest correlation coefficient are `Area_Indicator` of 0.31, `Installment_Percentage` of 0.22, `Annual_Income` and `Amount` of 0.2.\
Moreover, `Annual_Income` is associated with `Amount` forming a perfect positive relationship with the coefficient is 1. `Installment_Percentage` is associated with `Amount` and `Annual_Income` sharing a moderate negative relationship with the coefficient is -.55.

```{r fig.height=3, fig.width=4}
df_fac = df %>% dplyr::select(where(is.factor))
cramer = matrix(NA, ncol(df_fac), ncol(df_fac))

for (i in (1:ncol(df_fac))){
  for (j in (1:ncol(df_fac))){
    tab = table(df_fac[, i], df_fac[, j])
    chisq_results = chisq.test(tab)
    cramer[i, j] = sqrt(chisq_results$statistic/(nrow(df_fac) * (min(dim(tab)) -1)))
  }
}

cramer = round(cramer, 3)
colnames(cramer) = colnames(df_fac)
rownames(cramer) = colnames(df_fac)

corrplot(cramer, method = "shade", type = "upper", diag = F, tl.srt = 45,  tl.col = "black",
         tl.cex = 0.6, addCoef.col = "darkgreen", addCoefasPercent = T)
```

```{r}
df_num = df %>% dplyr::select(where(is.numeric))
df_num$Good_Customer = df$Good_Customer

model.matrix(~0+., data=df_num) %>% 
  cor(use="pairwise.complete.obs") %>% 
  ggcorrplot(show.diag = F, type="lower", lab=TRUE, lab_size=2) +
  theme(axis.text.x = element_text(size=8),
        axis.text.y = element_text(size=8))
```

# Predictive model
[Modeling q1]
Data is split into training and validation sets using an 80%/20% split.

```{r}
trainIndex <- createDataPartition(df$Good_Customer, p = .8, list = FALSE)
train <- df[ trainIndex,]
test  <- df[-trainIndex,]
```

### Functions for models

```{r echo=FALSE}
lr_imp_split = function(model){
  if (class(model)[1] == "ranger"){
    imp_df = model$variable.importance %>% 
      data.frame("Overall" = .) %>% 
      rownames_to_column() %>% 
      rename(variable = rowname) %>% 
      arrange(-Overall)
  } else {
    imp_df = varImp(model) %>%
      rownames_to_column() %>% 
      rename(variable = rowname) %>% 
      arrange(-Overall)
  }
  
  gg1 = imp_df %>% 
    slice(1:floor(nrow(.)/2)) %>% 
    ggplot() +
    aes(x = reorder(variable, Overall), weight = Overall, fill = -Overall) +
    geom_bar() +
    coord_flip() +
    xlab("Variables") +
    ylab("Importance") +
    theme(legend.position = "none")
  
  imp_range = ggplot_build(gg1)[["layout"]][["panel_params"]][[1]][["x.range"]]
  imp_gradient = scale_fill_gradient(limits = c(-imp_range[2], -imp_range[1]),
                                     low = "#132B43", 
                                     high = "#56B1F7")
  
  gg2 = imp_df %>% 
    slice(floor(nrow(.)/2)+1:nrow(.)) %>% 
    ggplot() +
    aes(x = reorder(variable, Overall), weight = Overall, fill = -Overall) +
    geom_bar() +
    coord_flip() +
    xlab("") +
    ylab("Importance") +
    theme(legend.position = "none") +
    ylim(imp_range) +
    imp_gradient
  
  gg_both = plot_grid(gg1 + imp_gradient,
                      gg2)
  
  return(gg_both)
}

lr_cutoff = function(score, obs, measure1, measure2) {
  predictions = prediction(score, obs)
  performance1 = performance(predictions, measure1)
  performance2 = performance(predictions, measure2)
  
  df1 = data.frame(x = performance1@x.values[[1]],
                   y = performance1@y.values[[1]],
                   measure = measure1,
                   stringsAsFactors = F) %>% 
    drop_na()
  df2 = data.frame(x = performance2@x.values[[1]],
                   y = performance2@y.values[[1]],
                   measure = measure2,
                   stringsAsFactors = F) %>% 
    drop_na()
  
  df = df1 %>% 
    bind_rows(df2)
  
  y_max_measure1 = max(df1$y, na.rm = T)
  x_max_measure1 = df1[df1$y == y_max_measure1, "x"][1]
  
  y_max_measure2 = max(df2$y, na.rm = T)
  x_max_measure2 = df2[df2$y == y_max_measure2, "x"][1]
  
  txt_measure1 = paste("Best cut for", measure1, ": x =", round(x_max_measure1, 3))
  txt_measure2 = paste("Best cut for", measure2, ": x =", round(x_max_measure2, 3))
  txt_tot = paste(txt_measure1, "\n", txt_measure2, sep = "")
  
  gg = df %>% 
    ggplot() +
    aes(x = x,
        y = y,
        colour = measure) +
    geom_line() +
    geom_vline(xintercept = c(x_max_measure1, x_max_measure2), linetype = "dashed", color = "gray") +
    geom_hline(yintercept = c(y_max_measure1, y_max_measure2), linetype = "dashed", color = "gray") +
    labs(caption = txt_tot) +
    theme(plot.caption = element_text(hjust = 0)) +
    xlim(c(0, 1)) +
    ylab("") +
    xlab("Threshold")
  
  return(gg)
}

lr_cut_pred = function(score, cut) {
  classes = score
  classes[classes > cut] = 1
  classes[classes <= cut] = 0
  classes = as.factor(classes)
  
  return(classes)  
}
```

## Logistic regression
[Modeling q3]
The logistic regression model is used to understand the relationship between the dependent variable `Good_Customer` and the independent variables. The logistic regression contains every remaining feature. It can be seen that a lot of features are non-significant in this model including `Annual_Income`, `Credit_History`, `Amount`, `Employment`, `Installment_Percentage` and `Existing_Credits`. The top 3 most important explanatory variables are `Area_Indicator` factor 4, 3 of 5.49 and 4.97 respectively, `Time_at_Current_Employment` of 4.96 and `Delayed_Missed_Payments` factor 1 of 4.1. `Installment_Percentage`, `Annual_Income` and `Amount` are not an essential variable anymore compared to the result in EDA.

```{r fig.height=2.5, fig.width=6}
set.seed(5312)
lr.fit <- glm(formula = Good_Customer ~ ., data = train, family=binomial)
summary(lr.fit)
lr_imp_split(lr.fit)
```

```{r eval=FALSE, include=FALSE}
varImp(lr.fit)
```

Then, both training and test data are used to evaluate how well did the training go. The validation scores will be used to validate the model.

```{r}
pred.lr.train = predict(lr.fit, newdata = train, type = "response")
pred.lr.test = predict(lr.fit, newdata = test, type = "response")
```

This plot shows the evolution of the accuracy and F1 score rates according to the cut level. The result should have a good F1 score without dropping too much on accuracy. The 0.2 cut seems a good settlement that is the trade-off between accuracy and F1 score.

```{r fig.height=3, fig.width=4}
train_score = lr_cutoff(pred.lr.train, train$Good_Customer, "acc", "f")
train_score + geom_vline(xintercept = c(0.2, 0.5), linetype = "dashed")
```

From the summary of the training set, the accuracy reaches 81.34% and the sensitivity rate is 67.48%, which means the model manages to correctly label 81.34% of the times and 67.48% of the good customers are correctly detected.

```{r}
lr_train_cut = 0.2
lr_train_class = lr_cut_pred(pred.lr.train, lr_train_cut)
confusionMatrix(lr_train_class, as.factor(as.numeric(c(0,1))[train$Good_Customer]), 
                                       positive = "1", mode = "everything")
```

## Validation for Logistic regression

```{r fig.height=3, fig.width=4}
test_score = lr_cutoff(pred.lr.test, test$Good_Customer, "acc", "f")
test_score + geom_vline(xintercept = c(lr_train_cut, 0.5), linetype = "dashed")
```
[Modeling q2]
The performance is close to the training set, which means it does not suffer from over fitting. From the summary of the test data set, the accuracy reaches 79.43% and the sensitivity rate is 64.71%, which means the model manages to correctly label 79.43% of the times and 64.71% of the good customers are correctly detected.\
While ensuring that 5% of the bad customers are wrongly identified, which is false negatives, the proportion of good customers that can be granted loans which is true positives (1-0.05) = 0.95. If 1% FN, TP is 0.99. If 0.5% FN, TP is 0.995. From the confusion matrix, since the sensitivity is 0.6471 while ensuring that (1-.6471) = 35.29% of the bad customers are wrongly identified.

```{r}
lr_test_class = lr_cut_pred(pred.lr.test, lr_train_cut)
confusionMatrix(lr_test_class, as.factor(as.numeric(c(0,1))[test$Good_Customer]), 
                                      positive = "1", mode = "everything")
```
